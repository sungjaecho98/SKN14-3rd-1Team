from langchain_tavily import TavilySearch
from langchain.agents import create_react_agent, AgentExecutor
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os

load_dotenv()

def get_recommendation_from_web(query: str, cfg):
    llm = ChatOpenAI(model=cfg['OPENAI_MODEL_NAME'], temperature=0)
    tavily_tool = TavilySearch(max_results=3)
    tools = [tavily_tool]

    # ğŸ”§ ì»¤ìŠ¤í…€ ReAct í”„ë¡¬í”„íŠ¸ ì„¤ì •
    REACT_PROMPT = """
ë‹¹ì‹ ì€ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì•„ë˜ ë„êµ¬ë“¤ì„ ì´ìš©í•´ ì§ˆë¬¸ì— ê°€ì¥ ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”:

{tools}

ë‹¤ìŒ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

Question: ì‚¬ìš©ìì˜ ì§ˆë¬¸
Thought: ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í• ì§€ ìƒê°
Action: ì‚¬ìš©í•  ë„êµ¬ (ë‹¤ìŒ ì¤‘ í•˜ë‚˜ [{tool_names}])
Action Input: ë„êµ¬ì— ì…ë ¥í•  ë‚´ìš©
Observation: ë„êµ¬ì˜ ì¶œë ¥ ê²°ê³¼
... (ì´ Thought/Action/Observation ê³¼ì •ì€ ë°˜ë³µ ê°€ëŠ¥)
Thought: ì´ì œ ìµœì¢… ë‹µë³€ì„ ì•Œê² ì–´ìš”
Final Answer: ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ (JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ 3ê°œì˜ ì œí’ˆì„ ë°˜í™˜)

- ìµœì¢… ì‘ë‹µì€ ë°˜ë“œì‹œ **ì„¤ëª… ì—†ì´ JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ, **ëª¨ë“  í•­ëª©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±**í•´ì£¼ì„¸ìš”.  
- ê°€ê²©ì€ ìˆ«ìí˜• + "ì›" ë‹¨ìœ„ë¡œ í‘œê¸°í•˜ê³ , `"price": 32000ì›`ì²˜ëŸ¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

- ì˜ˆì‹œ í˜•ì‹:

Final Answer:
[
  {{
    "name": "ì œí’ˆëª…",
    "brand": "ë¸Œëœë“œëª…",
    "price": "32000ì›",
    "ingredients": ["ì„±ë¶„1", "ì„±ë¶„2"],
    "benefits": ["íš¨ê³¼1", "íš¨ê³¼2"],
    "dosage": "ë³µìš©ë²• ì„¤ëª…",
    "warnings": ["ì£¼ì˜ì‚¬í•­1", "ì£¼ì˜ì‚¬í•­2"],
    "category": "ì¹´í…Œê³ ë¦¬ëª…",
    "rating": 4.5,
    "reviews": 123
  }},
  ...
]

Question: {input}
{agent_scratchpad}
"""

    prompt = PromptTemplate(
        input_variables=["input", "tools", "tool_names", "agent_scratchpad"],
        template=REACT_PROMPT
    )

    agent = create_react_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True
    )

    result = agent_executor.invoke({"input": query})
    return result["output"]
