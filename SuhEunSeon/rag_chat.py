# -*- coding: utf-8 -*-
"""data_refine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qO5cmLv-4W7TBNXBW1BOdGKwpSktEsLa
"""

# !pip install langchain langchain-openai langchain-pinecone langchain-community

#from google.colab import userdata
from langchain.prompts import PromptTemplate
from openai import OpenAI
import dotenv
from pinecone import Pinecone
from config import load_config
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Pinecone
import os, json
from langchain.schema import Document
from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain



cfg = load_config()
pc = Pinecone(api_key=cfg['PINECONE_API_KEY'], environment=cfg['PINECONE_ENV'])
embeddings = OpenAIEmbeddings(model=cfg['OPENAI_EMBEDDING_MODEL'])

"""## API -> 문서"""

import requests
from langchain_core.documents import Document

def json_to_documents(api_json: dict) -> list[Document]:
    documents = []

    for entry in api_json['body']['items']:
        data = entry['item']

        # Helper function to get and strip a value, handling None
        def get_and_strip(data_dict, key):
            value = data_dict.get(key)
            return value.strip() if isinstance(value, str) else ''

        # page_content 구성
        text = f"""
제품명: {get_and_strip(data, 'PRDUCT')}
제조사: {get_and_strip(data, 'ENTRPS')}
기능성: {get_and_strip(data, 'MAIN_FNCTN')}
섭취 시 주의사항: {get_and_strip(data, 'INTAKE_HINT1')}
보관조건: {get_and_strip(data, 'PRSRV_PD')}
유통기한: {get_and_strip(data, 'DISTB_PD')}
"""

        # metadata 구성
        metadata = {
            "등록일자": data.get("STTEMNT_NO"),
            "제조사": data.get("ENTRPS"),
            "기준규격": get_and_strip(data, "BASE_STANDARD")
        }

        # Document 생성
        documents.append(Document(page_content=text, metadata=metadata))

    return documents


def fetch_all_documents(api_url, api_key, num_of_rows=100) -> list[Document]:
    all_documents = []

    # 먼저 1페이지 호출
    params = {
        "ServiceKey": api_key,
        "pageNo": "1",
        "numOfRows": str(num_of_rows),
        "type": "json",
    }

    response = requests.get(api_url, params=params, timeout=10)
    response.raise_for_status()
    first_page = response.json()

    total_count = int(first_page['body']['totalCount'])
    total_pages = (total_count // num_of_rows) + (1 if total_count % num_of_rows else 0)

    # 1페이지 → Document 추출
    all_documents.extend(json_to_documents(first_page))

    # 2페이지부터 마지막 페이지까지 반복
    for page in range(2, total_pages + 1):
        params['pageNo'] = str(page)
        response = requests.get(api_url, params=params, timeout=10)
        response.raise_for_status()
        page_json = response.json()

        docs = json_to_documents(page_json)
        all_documents.extend(docs)
        print(f"📄 {page}/{total_pages} 페이지 수집 완료")

    print(f"\n✅ 총 {len(all_documents)}개의 Document 객체 생성 완료")
    return all_documents

url = 'http://apis.data.go.kr/1471000/HtfsInfoService03/getHtfsItem01'
api_key = 'nsfVX4dKQRFTeyldmuRefFQqL8xOsDkkyw8TsU4dA4fO9vq7Zl7JTbrakHnVYBqRG62CWBhhOVwBaGgCBbm3AA=='

documents = fetch_all_documents(url, api_key)
print(documents[0].page_content)
print(documents[0].metadata)

print(documents[41000].page_content)
print(documents[41000].metadata)

"""## 문서 -> 벡터스토어"""

# 문서로부터 벡터스토어 생성
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pinecone import Pinecone
import time
import os


# 임베딩 모델
embeddings = OpenAIEmbeddings(model=os.environ['OPENAI_EMBEDDING_MODEL'])

# 문서 분할
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
split_documents = text_splitter.split_documents(documents)

# Pinecone 생성
pinecone_api_key = os.environ.get('PINECONE_API_KEY')

pc = Pinecone(api_key=pinecone_api_key)

index_name = 'health-supplement-rag'

# index 만들어논거 없으면 새로 생성
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=embeddings.get_dimension(),
        metric='cosine'
    )
    #
    while not pc.describe_index(index_name).status['ready']:
        time.sleep(1)

vector_store = PineconeVectorStore(index_name=index_name, embedding=embeddings)

# 배치로 밀어 넣기
batch_size = 100  # 배치사이즈 지정
for i in range(0, len(split_documents), batch_size):
    batch = split_documents[i:i + batch_size]
    # vector_store.add_documents(batch)
    print(f"Added batch {i//batch_size + 1}/{(len(split_documents)//batch_size) + 1}")

print("\n✅ All documents added to Pinecone vector store.")

# 존재하는 인덱스에 접근/검색
from pprint import pprint

retriever = vector_store.as_retriever(
    search_type='similarity',
    search_kwargs={'k': 3} # 유사한 문서 3개까지 검색
)
pprint(retriever.invoke('피로개선에 도움이 되는 영양제는?'))

"""## RAG 구성 (Retriever + LLM → 최종 답변 생성) 단계"""

# 1. RAG용 프롬프트
rag_prompt = PromptTemplate.from_template("""
당신은 건강기능식품 및 영양제 추천 전문가입니다.

다음은 건강기능식품 관련 문서입니다:

{context}

위 문서를 바탕으로 아래 질문에 최대한 정확하고 신뢰성 있게 답변해주세요.
질문: "{question}"

- 반드시 문서의 내용을 기반으로만 답변하세요.
- 효과나 효능이 불확실한 내용은 언급하지 마세요.
- 사용자에게 도움이 될 수 있는 건강기능식품을 구체적으로 추천하세요.
- 말투는 친절하고 상냥하되, 정보는 정확하게 제공하세요.

※ 답변 마지막에 다음 문장을 붙이세요:
건강기능식품은 의약품이 아닙니다. 전문가와 상담하세요.
""")

# 2. fallback 프롬프트 (검색 결과 없을 때)
fallback_prompt = PromptTemplate.from_template("""
"{question}"에 대한 관련 정보를 찾을 수 없습니다.

정확한 정보를 제공하기 어려우므로, 섣부른 추천은 하지 않겠습니다.

건강기능식품은 의약품이 아닙니다. 전문가와 상담하세요.
""")

# 3. LLM 세팅
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
    model_name="gpt-4.1-mini",
    temperature=0.3,
    max_tokens=512
)

# 4. QA 체인 (stuff 방식)
from langchain.chains.question_answering import load_qa_chain
qa_chain = load_qa_chain(llm=llm, chain_type="stuff", prompt=rag_prompt)

# 5. fallback 체인
fallback_chain = LLMChain(llm=llm, prompt=fallback_prompt)

# 6. 최종 실행 체인 (문서 검색 → 있으면 QA, 없으면 fallback)
def custom_rag_executor(question: str):
    # 문서 검색
    docs = retriever.get_relevant_documents(question)

    if docs:
        # 검색 결과 있음 → QA 수행
        return qa_chain.run(input_documents=docs, question=question)
    else:
        # 검색 결과 없음 → fallback 수행
        return fallback_chain.run({"question": question})

# 7. 질문 실행
query = "똥이 안 나와"
response = custom_rag_executor(query)
print("\n챗봇 응답:")
print(response)
